{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" This notebook describes how one can use pickle library to save files so that the TensorFlow kernel can be used with Desi condition_spectra function. \n",
    "\n",
    "Saving files like this has two majpr advantages:\n",
    "\n",
    " (1) It saves a lot of time as one does not have to run the condition_spectra function everytime before training the network.\n",
    " \n",
    " (2) Since the DESI kernel has very limited compatability with TF and Keras. This allows the users to bypass that lack of cohesion and save files using the functions in DESI kernel and use TF on a different notebook or a seperate notebook without needing the functions of DESI Kernel\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) Run the condition_spectra function on DESI Kernel to get the desired conditioned spectra of SN and Hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from desispec.io import read_spectra\n",
    "from desitrip.preproc import rebin_flux, rescale_flux\n",
    "\n",
    "from glob import glob\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astropy.table import Table\n",
    "\n",
    "import os\n",
    "import platform\n",
    "\n",
    "mpl.rc('font', size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_spectra(coadd_files, truth_files):\n",
    "    \"\"\"Read DESI spectra, rebin to a subsampled logarithmic wavelength grid, and rescale.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    coadd_files : list or ndarray\n",
    "        List of FITS files on disk with DESI spectra.\n",
    "    truth_files : list or ndarray\n",
    "        Truth files.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fluxes : ndarray\n",
    "        Array of fluxes rebinned to a logarithmic wavelength grid.\n",
    "    \"\"\"\n",
    "    fluxes = None\n",
    "    \n",
    "    for cf, tf in zip(coadd_files, truth_files):\n",
    "        spectra = read_spectra(cf)\n",
    "        wave = spectra.wave['brz']\n",
    "        flux = spectra.flux['brz']\n",
    "        ivar = spectra.ivar['brz']\n",
    "        \n",
    "        truth = Table.read(tf, 'TRUTH')\n",
    "        truez = truth['TRUEZ']\n",
    "#         uid = truth ['TARGETID']\n",
    "#         # Pre-condition: remove spectra with NaNs and zero flux values.\n",
    "#         mask = np.isnan(flux).any(axis=1) | (np.count_nonzero(flux, axis=1) == 0)\n",
    "#         mask_idx = np.argwhere(mask)\n",
    "#         flux = np.delete(flux, mask_idx, axis=0)\n",
    "#         ivar = np.delete(ivar, mask_idx, axis=0)\n",
    "\n",
    "        # Rebin and rescale fluxes so that each is normalized between 0 and 1.\n",
    "        rewave, reflux, reivar = rebin_flux(wave, flux, ivar, truez, minwave=2500., maxwave=9500., nbins=150, log=True, clip=True)\n",
    "        rsflux = rescale_flux(reflux)\n",
    "\n",
    "        if fluxes is None:\n",
    "            fluxes = rsflux\n",
    "        else:\n",
    "            fluxes = np.concatenate((fluxes, rsflux))\n",
    "    \n",
    "    return fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snia_truth = np.sort(glob.glob((r'/global/project/projectdirs/desi/science/td/sim/bgs/180s/snia_airmass2*/*truth.fits')))\n",
    "snia_coadd = np.sort(glob.glob((r'/global/project/projectdirs/desi/science/td/sim/bgs/180s/snia_airmass2*/*coadd.fits')))\n",
    "snia_flux  = condition_spectra(snia_coadd, snia_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_truth = np.sort(glob.glob((r'/global/project/projectdirs/desi/science/td/sim/bgs/180s/hosts_airmass2*/*truth.fits')))\n",
    "host_files= np.sort(glob.glob((r'/global/project/projectdirs/desi/science/td/sim/bgs/180s/hosts_airmass2*/*coadd.fits')))\n",
    "host_flux  = condition_spectra(host_files, host_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the files:\n",
    "- After you have saved the spectra flux then we can now go on to using pickle to save the output\n",
    "- In this example notebook, I show how to save flux data using snia_flux, host_flux a np list that we obtained after using the condition_spectra function as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wb stands for 'write binary'; it bascially encrypts your data as binary.\n",
    "- In the first example belpow I am saving snia_flux from above as snia_flux_airmass2.data \n",
    "- .data specifies the extentsion and is needed\n",
    "\n",
    "### General structure for saving a file to_be_saved as new_saved.data :\n",
    "\n",
    "- address: address of the directory where you want to save your file\n",
    "\n",
    "<code>\n",
    "with open (r'address/ new_saved.data', 'wb') as whatever:\n",
    "    pickle.dump(to_be_saved, whatever)\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(r'/global/homes/v/vashisth/Binary/snia_flux_airmass2.data', 'wb') as f:\n",
    "    pickle.dump(snia_flux, f) \n",
    "    \n",
    "with open(r'/global/homes/v/vashisth/Binary/host_flux_airmass2.data', 'wb') as f:\n",
    "    pickle.dump(host_flux, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading pickled files\n",
    "- You can load the files after changing the kernel of the notebook or you can simply make a new notebook where you want to use <b>Tensorflow or anything that is not compatible with DESI Kernel</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General structure for loading a file new_saved.data as to_be_used :\n",
    "- Note: the pickled file (new_saved.data) needs to be in the same folder as where you want to it\n",
    "\n",
    "<code>\n",
    "with open (r'new_saved.data', 'rb') as whatever:\n",
    "    to_be_used= pickle.load(whatever)\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('host_flux_airmass2.data', 'rb') as filehandle:\n",
    "    host_flux = pickle.load(filehandle)\n",
    "\n",
    "with open('snia_flux_airmass2.data', 'rb') as filehandle:\n",
    "    # read the data as binary data stream\n",
    "    snia_flux = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> I hope this was useful !!!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (3.5.6)",
   "language": "python",
   "name": "python3-3.5.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
